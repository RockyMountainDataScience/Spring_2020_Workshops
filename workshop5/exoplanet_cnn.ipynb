{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanet Convolutional Neural Network (CNN) Classifier\n",
    "Here we will use a CNN to classify if a star observed by Kepler contains a exoplanet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/home/mike/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/mike/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/mike/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/mike/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/mike/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/mike/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
    }
   ],
   "source": [
    "import tensorflow.keras.models\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.layers import Embedding\n",
    "# from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets load the data and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    # Convert columns to something more useful.\n",
    "    for i, column in enumerate(data.columns):\n",
    "        if 'FLUX' in column:\n",
    "            data.columns.values[i] = int(column.split('.')[1])\n",
    "    # Also change labels so 0 is non-exoplanet and 1 is exoplanet\n",
    "    data.LABEL -= 1\n",
    "    return data\n",
    "\n",
    "def normalize_data(df):\n",
    "    \"\"\"\n",
    "    Normalize a Kepler light curve DatFrame with a mean subtraction and \n",
    "    \"\"\"\n",
    "    # Calculate the mean of each light curve and subtract it\n",
    "    df_norm = df.copy()\n",
    "    mean = df_norm.iloc[:, 1:].mean(axis=1)\n",
    "    df_norm.iloc[:, 1:] = df_norm.iloc[:, 1:].subtract(mean, axis=0)\n",
    "    # Calculate the standard deviation of each light curve and divide.\n",
    "    std = df_norm.iloc[:, 1:].std(axis=1)\n",
    "    df_norm.iloc[:, 1:] = df_norm.iloc[:, 1:].divide(std, axis=0)\n",
    "    return df_norm\n",
    "\n",
    "\n",
    "train_data = load_data('./data/exoTrain.csv')\n",
    "train_data = normalize_data(train_data)\n",
    "\n",
    "test_data = load_data('./data/exoTest.csv')\n",
    "test_data = normalize_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LABEL</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>3188</th>\n      <th>3189</th>\n      <th>3190</th>\n      <th>3191</th>\n      <th>3192</th>\n      <th>3193</th>\n      <th>3194</th>\n      <th>3195</th>\n      <th>3196</th>\n      <th>3197</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.521974</td>\n      <td>0.459509</td>\n      <td>0.063126</td>\n      <td>-0.229790</td>\n      <td>-0.308059</td>\n      <td>-0.837834</td>\n      <td>-0.902975</td>\n      <td>-0.660890</td>\n      <td>-0.558979</td>\n      <td>...</td>\n      <td>-0.547656</td>\n      <td>-0.697473</td>\n      <td>-0.697473</td>\n      <td>0.094421</td>\n      <td>0.240257</td>\n      <td>0.513824</td>\n      <td>0.182707</td>\n      <td>0.320205</td>\n      <td>-0.030324</td>\n      <td>-0.307935</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.524105</td>\n      <td>-0.439954</td>\n      <td>-0.851711</td>\n      <td>-0.544268</td>\n      <td>-1.197814</td>\n      <td>-1.089501</td>\n      <td>-1.318459</td>\n      <td>-1.298129</td>\n      <td>-1.275467</td>\n      <td>...</td>\n      <td>0.069120</td>\n      <td>-0.412959</td>\n      <td>-0.412959</td>\n      <td>-0.290981</td>\n      <td>0.042791</td>\n      <td>0.136440</td>\n      <td>-0.071188</td>\n      <td>0.231423</td>\n      <td>0.390394</td>\n      <td>0.455882</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.860570</td>\n      <td>1.872206</td>\n      <td>1.793484</td>\n      <td>1.733848</td>\n      <td>1.590274</td>\n      <td>1.624154</td>\n      <td>1.618833</td>\n      <td>1.696491</td>\n      <td>1.519711</td>\n      <td>...</td>\n      <td>-0.283383</td>\n      <td>0.018167</td>\n      <td>0.018167</td>\n      <td>-0.135091</td>\n      <td>-0.103127</td>\n      <td>-0.011101</td>\n      <td>-0.070914</td>\n      <td>-0.131615</td>\n      <td>-0.277459</td>\n      <td>-0.372004</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3.207775</td>\n      <td>3.409928</td>\n      <td>2.973657</td>\n      <td>2.932781</td>\n      <td>3.122729</td>\n      <td>3.073910</td>\n      <td>3.167189</td>\n      <td>3.060446</td>\n      <td>3.071198</td>\n      <td>...</td>\n      <td>0.100317</td>\n      <td>0.008878</td>\n      <td>0.008878</td>\n      <td>0.336081</td>\n      <td>0.239025</td>\n      <td>-0.077717</td>\n      <td>-0.039941</td>\n      <td>-0.122661</td>\n      <td>-0.123049</td>\n      <td>0.180422</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-2.684628</td>\n      <td>-2.697843</td>\n      <td>-2.713465</td>\n      <td>-2.654883</td>\n      <td>-2.562650</td>\n      <td>-2.505984</td>\n      <td>-2.417214</td>\n      <td>-2.477073</td>\n      <td>-2.395673</td>\n      <td>...</td>\n      <td>-1.424955</td>\n      <td>-0.951607</td>\n      <td>-0.951607</td>\n      <td>-0.842499</td>\n      <td>-1.055016</td>\n      <td>-1.042194</td>\n      <td>-0.946817</td>\n      <td>-0.909826</td>\n      <td>-0.976489</td>\n      <td>-1.219045</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3198 columns</p>\n</div>",
      "text/plain": "   LABEL         1         2         3         4         5         6  \\\n0      1  0.521974  0.459509  0.063126 -0.229790 -0.308059 -0.837834   \n1      1 -0.524105 -0.439954 -0.851711 -0.544268 -1.197814 -1.089501   \n2      1  1.860570  1.872206  1.793484  1.733848  1.590274  1.624154   \n3      1  3.207775  3.409928  2.973657  2.932781  3.122729  3.073910   \n4      1 -2.684628 -2.697843 -2.713465 -2.654883 -2.562650 -2.505984   \n\n          7         8         9  ...      3188      3189      3190      3191  \\\n0 -0.902975 -0.660890 -0.558979  ... -0.547656 -0.697473 -0.697473  0.094421   \n1 -1.318459 -1.298129 -1.275467  ...  0.069120 -0.412959 -0.412959 -0.290981   \n2  1.618833  1.696491  1.519711  ... -0.283383  0.018167  0.018167 -0.135091   \n3  3.167189  3.060446  3.071198  ...  0.100317  0.008878  0.008878  0.336081   \n4 -2.417214 -2.477073 -2.395673  ... -1.424955 -0.951607 -0.951607 -0.842499   \n\n       3192      3193      3194      3195      3196      3197  \n0  0.240257  0.513824  0.182707  0.320205 -0.030324 -0.307935  \n1  0.042791  0.136440 -0.071188  0.231423  0.390394  0.455882  \n2 -0.103127 -0.011101 -0.070914 -0.131615 -0.277459 -0.372004  \n3  0.239025 -0.077717 -0.039941 -0.122661 -0.123049  0.180422  \n4 -1.055016 -1.042194 -0.946817 -0.909826 -0.976489 -1.219045  \n\n[5 rows x 3198 columns]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LABEL</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>3188</th>\n      <th>3189</th>\n      <th>3190</th>\n      <th>3191</th>\n      <th>3192</th>\n      <th>3193</th>\n      <th>3194</th>\n      <th>3195</th>\n      <th>3196</th>\n      <th>3197</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3.996087</td>\n      <td>3.336384</td>\n      <td>2.875229</td>\n      <td>1.608144</td>\n      <td>1.522286</td>\n      <td>1.296571</td>\n      <td>0.598300</td>\n      <td>0.209588</td>\n      <td>0.197850</td>\n      <td>...</td>\n      <td>0.462469</td>\n      <td>0.622447</td>\n      <td>0.459785</td>\n      <td>-0.078843</td>\n      <td>0.422558</td>\n      <td>1.501492</td>\n      <td>1.046374</td>\n      <td>1.175497</td>\n      <td>9.011772</td>\n      <td>1.911332</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3.429247</td>\n      <td>3.406992</td>\n      <td>3.417435</td>\n      <td>3.402585</td>\n      <td>3.385016</td>\n      <td>3.365156</td>\n      <td>3.362257</td>\n      <td>3.327655</td>\n      <td>3.316087</td>\n      <td>...</td>\n      <td>-0.411742</td>\n      <td>-0.656225</td>\n      <td>-0.806254</td>\n      <td>-1.030908</td>\n      <td>-1.167125</td>\n      <td>-1.310978</td>\n      <td>-1.435481</td>\n      <td>-1.496398</td>\n      <td>-1.453037</td>\n      <td>-1.294899</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>7.264587</td>\n      <td>7.034055</td>\n      <td>6.629022</td>\n      <td>5.817077</td>\n      <td>5.223535</td>\n      <td>4.317549</td>\n      <td>3.816340</td>\n      <td>3.151648</td>\n      <td>1.821924</td>\n      <td>...</td>\n      <td>0.203756</td>\n      <td>-0.389700</td>\n      <td>-0.360916</td>\n      <td>-0.460850</td>\n      <td>-0.649700</td>\n      <td>-1.439267</td>\n      <td>-0.761849</td>\n      <td>-1.337966</td>\n      <td>-0.262689</td>\n      <td>0.313171</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-1.936512</td>\n      <td>-1.939833</td>\n      <td>-1.987513</td>\n      <td>-1.961937</td>\n      <td>-1.732460</td>\n      <td>-1.831799</td>\n      <td>-1.848352</td>\n      <td>-1.734995</td>\n      <td>-1.641283</td>\n      <td>...</td>\n      <td>0.467350</td>\n      <td>0.393055</td>\n      <td>0.393055</td>\n      <td>0.331662</td>\n      <td>0.182108</td>\n      <td>0.209839</td>\n      <td>0.208571</td>\n      <td>-0.148989</td>\n      <td>-0.495625</td>\n      <td>-0.388782</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-0.089813</td>\n      <td>0.043997</td>\n      <td>0.081954</td>\n      <td>0.097712</td>\n      <td>0.042585</td>\n      <td>-0.002150</td>\n      <td>0.128609</td>\n      <td>-0.121613</td>\n      <td>0.105225</td>\n      <td>...</td>\n      <td>-0.080210</td>\n      <td>-0.215658</td>\n      <td>-0.019660</td>\n      <td>0.014060</td>\n      <td>-0.056996</td>\n      <td>-0.348337</td>\n      <td>-0.326422</td>\n      <td>-0.216392</td>\n      <td>-0.257964</td>\n      <td>0.032926</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3198 columns</p>\n</div>",
      "text/plain": "   LABEL         1         2         3         4         5         6  \\\n0      1  3.996087  3.336384  2.875229  1.608144  1.522286  1.296571   \n1      1  3.429247  3.406992  3.417435  3.402585  3.385016  3.365156   \n2      1  7.264587  7.034055  6.629022  5.817077  5.223535  4.317549   \n3      1 -1.936512 -1.939833 -1.987513 -1.961937 -1.732460 -1.831799   \n4      1 -0.089813  0.043997  0.081954  0.097712  0.042585 -0.002150   \n\n          7         8         9  ...      3188      3189      3190      3191  \\\n0  0.598300  0.209588  0.197850  ...  0.462469  0.622447  0.459785 -0.078843   \n1  3.362257  3.327655  3.316087  ... -0.411742 -0.656225 -0.806254 -1.030908   \n2  3.816340  3.151648  1.821924  ...  0.203756 -0.389700 -0.360916 -0.460850   \n3 -1.848352 -1.734995 -1.641283  ...  0.467350  0.393055  0.393055  0.331662   \n4  0.128609 -0.121613  0.105225  ... -0.080210 -0.215658 -0.019660  0.014060   \n\n       3192      3193      3194      3195      3196      3197  \n0  0.422558  1.501492  1.046374  1.175497  9.011772  1.911332  \n1 -1.167125 -1.310978 -1.435481 -1.496398 -1.453037 -1.294899  \n2 -0.649700 -1.439267 -0.761849 -1.337966 -0.262689  0.313171  \n3  0.182108  0.209839  0.208571 -0.148989 -0.495625 -0.388782  \n4 -0.056996 -0.348337 -0.326422 -0.216392 -0.257964  0.032926  \n\n[5 rows x 3198 columns]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ballance the data set we create a batch function to return equal number of exoplanet and non-exoplanet light curves. There will be duplicate light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_curve_batch(train_df, batch_size=32):\n",
    "    \"\"\"\n",
    "    Returns equal number of random exoplanets and non-exoplanet detections.\n",
    "    \"\"\"\n",
    "    exo_df = train_df[train_df.LABEL == 1].sample(n=batch_size//2, \n",
    "        random_state=123, replace=True)\n",
    "    nonexo_df = train_df[train_df.LABEL == 0].sample(n=batch_size//2,\n",
    "        random_state=123, replace=True)\n",
    "    df = pd.concat([exo_df, nonexo_df])\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    light_curves = df.iloc[:, 1:]\n",
    "    labels = df.iloc[:, 0]\n",
    "    return [light_curves.values], labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tensorflow.keras.models.Sequential()\n",
    "model1.add(Conv1D(filters=8, kernel_size=11, activation='relu', input_shape=(train_data.shape[1], 1)))\n",
    "model1.add(MaxPooling1D(strides=4))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_8_input to have shape (3198, 1) but got array with shape (32, 3197)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b6e72f7df6d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                            steps_per_epoch=train_data.shape[1]//32)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2426\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    519\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    522\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_8_input to have shape (3198, 1) but got array with shape (32, 3197)"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = model1.fit(light_curve_batch(train_data, 32), \n",
    "                           validation_data=(test_data.iloc[:, 1:].values, test_data.iloc[:, 0].values), \n",
    "                           verbose=0, epochs=5,\n",
    "                           steps_per_epoch=train_data.shape[1]//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5087, 3198)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}