{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Outline\n",
    "\n",
    "## Intro to club \n",
    "Welcome back, club directors intro, github account\n",
    "\n",
    "## Intro to Spring Semester \n",
    "Goal - to work on some data science projects together  \n",
    "Objectives - write code collaboratively while learning about different data science techniques and tools\n",
    "Workshop list\n",
    "\n",
    "## Data Science Project Components\n",
    "Pieces to the project puzzle  \n",
    "1. Data collection \n",
    "2. Data cleaning\n",
    "3. Picking an analysis model\n",
    "4. Running the model\n",
    "5. Interpreting the results  \n",
    "\n",
    "How do the pieces fit together? \n",
    "\n",
    "## User Based Collaborative Filtering with Movie Ratings\n",
    "Goal: 2 parts - (1) build movie suggestions for user based on their ratings and items consumed by similar users and (2) predict ratings in a test set based on user ratings and items consumed by similar users\n",
    "\n",
    "These are called \"TopN\" and \"Prediction\" tasks in Recommender Systems, respectively. \n",
    "We'll focus on the prediction task. \n",
    "\n",
    "### Steps:: \n",
    "\n",
    "1. Find a database of movie ratings (e.g., https://grouplens.org/datasets/movielens/100k/)\n",
    "        - Need at least (user,item,rating) tuples in dataset \n",
    "2. Split train/test sets \n",
    "        - If using link above, already split into stable 5-fold CV datasets\n",
    "        - Ultimate objections: for each observation in test set, we want rating prediction given user and item\n",
    "3. Build user-by-item matrix \n",
    "        - Reshape original dataset\n",
    "        - Rating values go in user-by-item matrix element\n",
    "        - Missing values are NAs (can impute 0) \n",
    "4. Choose a similarity measure\n",
    "        - Popular options: Pearson Correlation Coefficient (pairwise comparison or imputed zero), Cosine Vector Similarity\n",
    "        - These can get exotic \n",
    "5. Produce user-user similarity matrix \n",
    "        - For Pearson/Cosine, think: user-by-item x item-by-user => user-user\n",
    "6. For each test set observation (user_u,item_i,rating_ui) \n",
    "        - find nearest neighbors of user_u that have rated item_i\n",
    "        - select k of those neighbors\n",
    "        - average (or weighted average) the ratings of those neighbors\n",
    "        - Error? How to measure error between r_ui prediction and rating_ui? RMSE, MAE, something else? \n",
    "7. Abstract the previous step to loop over k values\n",
    "        - It's common to use granular values between 1-20\n",
    "        - Often go out as far as 100-150, by increments of 10-25\n",
    "8. Produce a plot corresponding to 7 with x values as k and y values as error\n",
    "        - Optimal k values? \n",
    "        - Describe the relationship\n",
    "9. Rinse and repeat for all train/test splits\n",
    "        - If you have to build a production quality system, how would you choose k? Would you choose k? \n",
    "        - Repeat experiment with other similarity measures\n",
    "        - Anything surprising? \n",
    "        - Bottlenecks?\n",
    "        - Effects of imputing? \n",
    "        - Could perform item-item similarity (in step 5 instead), thoughts? \n",
    "\n",
    "\n",
    "### Goal for today:: Get movie ratings data and manipulate format to calculate similarity\n",
    "\n",
    "1. Find a collection of movie ratings\n",
    "2. Download the information\n",
    "3. Inspect how the information is stored\n",
    "4. Prepare data\n",
    "5. Explore similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in the data file - first input is filename, \n",
    "# need to use the filepath to the file you want to load\n",
    "data = pd.read_table('u1.base',sep = '\\t', header = None)\n",
    "# don't forget to read in u1.test as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate data into a numpy array where\n",
    "# each row represents the ratings of one user,\n",
    "# each column represents the ratings of one movie across all users\n",
    "# this is typically referred to as a \"ratings matrix\" or \"user-by-item rating matrix\"\n",
    "data_array = np.zeros((max(data[0]),max(data[1])))\n",
    "for i in range(0,data.shape[0]):\n",
    "    data_array[data[0][i]-1][data[1][i]-1] = data[2][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Pearson cross-correlation coefficient matrix\n",
    "data_corr = np.corrcoef(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps: 6-9 from given above (and pasted below)\n",
    "\n",
    "6. For each test set observation (user_u,item_i,rating_ui) \n",
    "        - find nearest neighbors of user_u that have rated item_i\n",
    "        - select k of those neighbors\n",
    "        - average (or weighted average) the ratings of those neighbors\n",
    "        - Error? How to measure error between r_ui prediction and rating_ui? RMSE, MAE, something else? \n",
    "7. Abstract the previous step to loop over k values\n",
    "        - It's common to use granular values between 1-20\n",
    "        - Often go out as far as 100-150, by increments of 10-25\n",
    "8. Produce a plot corresponding to 7 with x values as k and y values as error\n",
    "        - Optimal k values? \n",
    "        - Describe the relationship\n",
    "9. Rinse and repeat for all train/test splits\n",
    "        - If you have to build a production quality system, how would you choose k? Would you choose k? \n",
    "        - Repeat experiment with other similarity measures\n",
    "        - Anything surprising? \n",
    "        - Bottlenecks?\n",
    "        - Effects of imputing? \n",
    "        - Could perform item-item similarity (in step 5 instead), thoughts? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
