{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification via Neural Network\n",
    "\n",
    "To build the neural network are going to use the TensorFlow library. Along the way we will talk about how to use a neural network to solve a classification problem, and the choices made when building a neural network.\n",
    "\n",
    "Tensorflow is a numerical computation library that focuses on machine learning models. It is written in Python but uses C++ for speed with large scale data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efRYtZ1YKOax"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this clears some errors, but isn't necessary for the rest\n",
    "pip install \"numpy<1.17\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6ovxd9JTps-"
   },
   "source": [
    "## Get the data \n",
    "* We can do this by applying the load_data method on the mnist data in keras\n",
    "* By default, the data has been split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLBDVJ3QT7ko"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcBuojv7UlJT"
   },
   "source": [
    "## Explore the data\n",
    "* Check the shape (the dimensions of the data)\n",
    "* View an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "dFMeeNQgT_L6",
    "outputId": "8a079e83-85b2-411e-a39b-ecd66ba5eebc"
   },
   "outputs": [],
   "source": [
    "print('Shape of training data: ' ,X_train.shape)\n",
    "print('Amount of testing data: ' , len(X_test))\n",
    "print('Shape of training classifications: ' , y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4djfKmaVJwp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "num = 147\n",
    "print('Classification is ', y_train[num])\n",
    "img = np.reshape(X_train[num], (28, 28))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2Wou3yxWfAd"
   },
   "source": [
    "## Reshape the data\n",
    "* Since we are using a fully connected layer which has shape = (samples, features), we need to reshape the training and test samples to suit that dimension.\n",
    "* Also, we will scale our values to be in [0,1] interval and convert to float32.\n",
    "* Previously, the values are of type unit8 and in the [0, 255].\n",
    "* Also, reshape the labels to have categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCgifH1ZXHiu"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((60000, 28 * 28))\n",
    "X_train = X_train.astype('float32')/255\n",
    "\n",
    "X_test = X_test.reshape((10000, 28 * 28))\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "\n",
    "# reshape the labels\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AoGj_8f_Z8LS"
   },
   "source": [
    "## Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "tqHMs896X7fg",
    "outputId": "497be2b6-bf15-43e4-8906-c2a41926199d"
   },
   "outputs": [],
   "source": [
    "print(X_train[:10])\n",
    "plt.imshow(np.reshape(X_train[0],(28,28)),cmap='gray')\n",
    "print(\"Our labels have {} classes\".format(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFhGqIBicVTz"
   },
   "source": [
    "## Build your architecture\n",
    "We are using the sequential model in keras which involves stacking up the layers sequentially.\n",
    "* Here, we are using 3 fully connected layers\n",
    "* Specify the activation function (e.g. Relu)\n",
    "* Specify the number of nodes in each hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAst4ZnFaNpD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# instantiate the model\n",
    "model = Sequential() \n",
    "\n",
    "# the first layer is where we specify the input shape\n",
    "model.add(Dense(512, activation = 'relu', input_shape = (28 * 28, )))  \n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "# in the last layer, we specify number of labels to expect\n",
    "model.add(Dense(10, activation = 'softmax'))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jkx9FH48eODw"
   },
   "source": [
    "## Compile the network\n",
    "* Here, we specify the optimizer to use for our weight update (e.g. RMSprop)\n",
    "* Specify the loss function (e.g. categorical_crossentropy)\n",
    "* Metrics to monitor (e.g. accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLBZhUVWeKZg"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zhrwe2UKe9BB"
   },
   "source": [
    "## Fit the model\n",
    "* specify the number of epochs; epochs refers to the number of iteration to train all the data.\n",
    "* batch size: batches of data to use for training at a time\n",
    "  \n",
    "After the model is trained, we will plot some metrics to see how things changed during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "9r8cfYnte7gp",
    "outputId": "4aeff01e-0c46-4813-efb2-c33146cf42b4"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 5, batch_size = 128)\n",
    "\n",
    "# plot some metrics\n",
    "fig = plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J25Vpe0dglfx"
   },
   "source": [
    "## Evaluate the model's performance\n",
    "* Examine the model's performance on the test data to see if it overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jxLWWy_Yfxp-",
    "outputId": "87d9126a-cc62-4aac-ba50-7997ae9f175c"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy is {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7YZyX-4ZhYYB"
   },
   "source": [
    "## Save your model\n",
    "* It is a good practice to save your model\n",
    "* To reuse your saved model, type: from keras.models import load_model\n",
    "* Then, load_model('model name')\n",
    "* The saved model saves the layers used with the network updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcAwE61YhQsC"
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yz6NEhejbQx"
   },
   "source": [
    "## Generate predictions\n",
    "* Use the testing data to see the model's predictions\n",
    "* Display a test image and its prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNmZN5EAje8e"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "img = np.reshape(X_test[4],(28,28))\n",
    "plt.imshow(img)\n",
    "print('Predicted: ',predictions[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Tasks\n",
    "1. Modify the network architecture by changing the number of layers, the number of nodes, and/or the activation function. Do your changes help or hurt the accuracy?\n",
    "2. Modify the model fit by changing the number of epochs and/or batch_size. Do your changes help or hurt the accuracy?\n",
    "3. Try building a model for the MNIST Fashion dataset, which has clothing classifications instead of digits. You will need to load the MNIST Fashion data, build an architecture then compile and fit a model. Then you can inspect accuracy and visualize your predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
